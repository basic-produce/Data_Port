{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections + Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'QTHONG'\n",
    "database = 'SC_Pipeline'\n",
    "connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "params = quote_plus(connection_string)\n",
    "sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
    "engine = create_engine(sqlalchemy_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['consignment_by_customer.csv', 'dim_customer.csv', 'dim_material.csv', 'log_shipment_rec.csv', 'po_by _vendor.csv', 'so_by_customer.csv', 'stock_by_material.csv', 'sto_rec.csv', 'weekly_open_order.csv']\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "csv_directory = os.path.join(pwd, \"data\")  # The path to  CSV files\n",
    "print(os.listdir(csv_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Excel Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_serial_date_to_datetime(serial_date):\n",
    "    try:\n",
    "        serial_date = float(serial_date)  # Ensure the value is a float\n",
    "        base_date = datetime(1899, 12, 30)\n",
    "        delta = timedelta(days=serial_date)\n",
    "        return base_date + delta\n",
    "    except ValueError:\n",
    "        # Return None or some default value if conversion fails\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle String Date + Excel Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_column(date_value):\n",
    "    if pd.isnull(date_value):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Attempt to convert the value to float, indicating it could be an Excel serial date\n",
    "        numeric_value = float(date_value)\n",
    "        return excel_serial_date_to_datetime(numeric_value)\n",
    "    except ValueError:\n",
    "        # If conversion fails, attempt to parse as a string-formatted date\n",
    "        return pd.to_datetime(date_value, errors='coerce', dayfirst=True)  # Assuming day-first format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_and_create_table(file_path, table_name, date_columns=None):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Clean the column names\n",
    "        df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "        # Iterate over known date columns and convert them\n",
    "        if date_columns:\n",
    "            for col in date_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].apply(convert_date_column)\n",
    "        \n",
    "        # Insert data into the database\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False, method=None)\n",
    "        print(f'Imported {file_path} into {table_name}')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\consignment_by_customer.csv into consignment_by_customer\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\dim_customer.csv into dim_customer\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\dim_material.csv into dim_material\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\log_shipment_rec.csv into log_shipment_rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phamt\\AppData\\Local\\Temp\\ipykernel_18012\\87096264.py:11: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_value, errors='coerce', dayfirst=True)  # Assuming day-first format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\po_by _vendor.csv into po_by__vendor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phamt\\AppData\\Local\\Temp\\ipykernel_18012\\87096264.py:11: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(date_value, errors='coerce', dayfirst=True)  # Assuming day-first format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\so_by_customer.csv into so_by_customer\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\stock_by_material.csv into stock_by_material\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\sto_rec.csv into sto_rec\n",
      "Imported c:\\Users\\phamt\\Documents\\3000_a_month\\Data Analyst\\Personal projects\\Portfoilo projects\\Full Data Pipelines\\data\\weekly_open_order.csv into weekly_open_order\n"
     ]
    }
   ],
   "source": [
    "# known_date_columns = ['Document_Date', 'Delivery_Date', 'Date','Date_Entered','Revised_Due_Date','ESD']\n",
    "for csv_file in os.listdir(csv_directory):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, csv_file)\n",
    "        table_name = os.path.splitext(csv_file)[0].replace(' ', '_').replace('-', '_')\n",
    "        \n",
    "        # If you can specify date columns directly\n",
    "        read_csv_and_create_table(file_path, table_name, date_columns=known_date_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
